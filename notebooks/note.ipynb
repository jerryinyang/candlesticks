{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "\n",
    "cwd = Path.cwd()\n",
    "data_path = cwd.parent / 'data' / 'clean'\n",
    "# raw_df = pd.read_parquet(data_path / 'btcusdt.parquet') # BTCUSDT\n",
    "raw_df = pd.read_parquet(data_path / 'usdcad.parquet')\n",
    "raw_df['time'] = pd.to_datetime(raw_df['time'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CODE FOR PATTERN RECOGNITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASSES\n",
    "class Signal:\n",
    "    \"\"\"\n",
    "    A class to represent a trading signal.\n",
    "\n",
    "    Attributes:\n",
    "    - pattern (str): The pattern code.\n",
    "    - target (int): The target count.\n",
    "    - success_rate (float): The success rate of the pattern.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pattern: str, target: int, success_rate: float):\n",
    "        \"\"\"\n",
    "        Constructs all the necessary attributes for the Signal object.\n",
    "\n",
    "        Parameters:\n",
    "        - pattern (str): The pattern code.\n",
    "        - target (int): The target count.\n",
    "        - success_rate (float): The success rate of the pattern.\n",
    "        \"\"\"\n",
    "        self.pattern = pattern\n",
    "        self.target = target\n",
    "        self.success_rate = success_rate\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Signal(pattern={self.pattern}, target={self.target}, success_rate={self.success_rate})\"\n",
    "    \n",
    "    def __gt__(self, other):\n",
    "        return self.success_rate > other.success_rate\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.success_rate < other.success_rate\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return self.success_rate == other.success_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS\n",
    "def read_asset_data(asset_name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads asset data from a parquet file.\n",
    "\n",
    "    Parameters:\n",
    "    - asset_name (str): The name of the asset.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame containing the asset data if the file exists, otherwise an empty DataFrame.\n",
    "    \"\"\"\n",
    "    assert isinstance(asset_name, str), \"asset_name must be a string.\"\n",
    "\n",
    "    # Convert asset name to lowercase\n",
    "    asset_name = asset_name.lower()\n",
    "    \n",
    "    # Construct the path to the parquet file\n",
    "    parquet_path = Path(f\"data/clean/{asset_name}.parquet\")\n",
    "    \n",
    "    # Check if the file exists and read the parquet file\n",
    "    if Path.exists(parquet_path):\n",
    "        return pd.read_parquet(parquet_path)\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "\n",
    "def resample_data(data: pd.DataFrame, timeframe: str, datetime_col: Optional[str] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Resamples 1-minute OHLC data into a given timeframe.\n",
    "    \n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): A DataFrame containing 1-minute OHLC data with a DatetimeIndex or a datetime column.\n",
    "                           The columns should be ['open', 'high', 'low', 'close'].\n",
    "    - timeframe (str): The resampling timeframe, e.g., '5T', '15T', '30T', '1H', '2H', '4H', '8H', '1D', '1W'.\n",
    "    - datetime_col (str): The name of the column to use as the datetime index if the index is not a DatetimeIndex.\n",
    "    \n",
    "    Returns:\n",
    "    - resampled_data (pd.DataFrame): A DataFrame with the resampled OHLC data.\n",
    "    \"\"\"\n",
    "    # Create a copy of the data to avoid modifying the original DataFrame\n",
    "    data = data.copy()\n",
    "\n",
    "    # Ensure the timeframe is in uppercase\n",
    "    timeframe = timeframe.lower()\n",
    "    \n",
    "    # Check if the DataFrame has the correct columns\n",
    "    required_columns = ['open', 'high', 'low', 'close']\n",
    "    if not all(col in data.columns for col in required_columns):\n",
    "        raise ValueError(f\"Input data must contain the following columns: {required_columns}\")\n",
    "    \n",
    "    # If datetime_col is provided, set it as the index\n",
    "    if datetime_col:\n",
    "        if datetime_col not in data.columns:\n",
    "            raise ValueError(f\"The specified datetime column '{datetime_col}' is not in the DataFrame.\")\n",
    "        data[datetime_col] = pd.to_datetime(data[datetime_col])\n",
    "        data.set_index(datetime_col, inplace=True)\n",
    "    \n",
    "    # Check if the index is a DatetimeIndex\n",
    "    if not isinstance(data.index, pd.DatetimeIndex):\n",
    "        raise TypeError(\"Index of the DataFrame must be a DatetimeIndex or a valid datetime column must be provided.\")\n",
    "    \n",
    "    # Define the aggregation dictionary for resampling\n",
    "    ohlc_dict = {\n",
    "        'open': 'first',\n",
    "        'high': 'max',\n",
    "        'low': 'min',\n",
    "        'close': 'last'\n",
    "    }\n",
    "    \n",
    "    # Perform the resampling\n",
    "    resampled_data = data.resample(timeframe).apply(ohlc_dict).dropna(how='any')\n",
    "    resampled_data.reset_index(inplace=True, names=[datetime_col])\n",
    "    \n",
    "    return resampled_data\n",
    "\n",
    "\n",
    "def compare_values(value_1: float, value_2: float) -> str:\n",
    "    \"\"\"\n",
    "    Compares two float values and returns '1' if the first value is greater, else returns '0'.\n",
    "    \n",
    "    Parameters:\n",
    "    - value_1 (float): The first value to compare.\n",
    "    - value_2 (float): The second value to compare.\n",
    "    \n",
    "    Returns:\n",
    "    - (str): '1' if value_1 is greater than value_2, otherwise '0'.\n",
    "    \"\"\"\n",
    "    if value_1 > value_2:\n",
    "        return '1'\n",
    "    else:\n",
    "        return '0'\n",
    "\n",
    "\n",
    "def filled(price: float, high: float, low: float) -> bool:\n",
    "    \"\"\"\n",
    "    Checks if a price is within the high and low range.\n",
    "\n",
    "    Parameters:\n",
    "    - price (float): The price to check.\n",
    "    - high (float): The high range value.\n",
    "    - low (float): The low range value.\n",
    "\n",
    "    Returns:\n",
    "    - (bool): True if price is within the range, False otherwise.\n",
    "    \"\"\"\n",
    "    return (price <= high) and (price >= low)\n",
    "\n",
    "\n",
    "def find_patterns(df: pd.DataFrame, hold_period: int, oos_date_start: str, extra_targets: bool=True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Identifies and counts specific patterns in OHLC data over a given holding period.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): DataFrame containing OHLC data with columns ['time', 'open', 'high', 'low', 'close'].\n",
    "    - hold_period (int): The holding period to calculate rolling highest and lowest prices.\n",
    "    - oos_date_start (str): The out-of-sample start date to filter the DataFrame.\n",
    "    - extra_targets (bool): Whether to include extra targets in the output DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - pattern_labels (list): List of pattern labels for each row in the DataFrame.\n",
    "    - count_totals (dict): Dictionary with counts of each pattern found.\n",
    "    - count_success (dict): Dictionary with success counts for each pattern in different categories.\n",
    "    \"\"\"\n",
    "    # Preprocess the data\n",
    "    df = df.copy()\n",
    "\n",
    "    # Calculate rolling highest and lowest prices\n",
    "    df['highest'] = df['high'].rolling(hold_period).max()\n",
    "    df['lowest'] = df['low'].rolling(hold_period).min()\n",
    "\n",
    "    # Store patterns and their statistics\n",
    "    count_totals = {}\n",
    "    count_success = {}\n",
    "    pattern_labels = np.zeros(len(df), dtype=object)\n",
    "\n",
    "    # Iterate through the DataFrame\n",
    "    for i in range(hold_period + 1, len(df)):\n",
    "\n",
    "        bar_0 = df.iloc[i - hold_period]\n",
    "        bar_1 = df.iloc[i - hold_period - 1]\n",
    "\n",
    "        _highest = df['highest'].iloc[i]\n",
    "        _lowest = df['lowest'].iloc[i]\n",
    "\n",
    "        # Generate pattern string\n",
    "        _pattern = \\\n",
    "            compare_values(bar_0['high'], bar_1['high']) + \\\n",
    "            compare_values(bar_0['low'], bar_1['low']) + \\\n",
    "            compare_values(bar_0['open'], bar_1['open']) + \\\n",
    "            compare_values(bar_0['close'], bar_1['close']) + \\\n",
    "            compare_values(bar_0['open'], bar_1['close']) + \\\n",
    "            compare_values(bar_0['close'], bar_1['open'])\n",
    "        \n",
    "        # Add the pattern to the list of labels\n",
    "        pattern_labels[i - hold_period] = _pattern\n",
    "\n",
    "        # Filter DataFrame for in-sample data\n",
    "        if df.loc[i, 'time'] >= pd.to_datetime(oos_date_start):\n",
    "            continue\n",
    "        \n",
    "        # Initialize pattern in the dictionaries if not present\n",
    "        if _pattern not in count_totals:\n",
    "            count_totals[_pattern] = 0\n",
    "            count_success[_pattern] = {\n",
    "                'open': 0,\n",
    "                'high': 0,\n",
    "                'low': 0,\n",
    "            }\n",
    "\n",
    "        # Update the count of the pattern\n",
    "        count_totals[_pattern] += 1\n",
    "        \n",
    "        # Check and update success counts\n",
    "        if filled(bar_0['open'], _highest, _lowest):\n",
    "            count_success[_pattern]['open'] += 1\n",
    "        if filled(bar_0['high'], _highest, _lowest):\n",
    "            count_success[_pattern]['high'] += 1\n",
    "        if filled(bar_0['low'], _highest, _lowest):\n",
    "            count_success[_pattern]['low'] += 1\n",
    "        \n",
    "        if extra_targets:\n",
    "            if filled(bar_1['open'], _highest, _lowest):\n",
    "                count_success[_pattern]['open_1'] = count_success[_pattern].get('open_1', 0) + 1\n",
    "            if filled(bar_1['high'], _highest, _lowest):\n",
    "                count_success[_pattern]['high_1'] = count_success[_pattern].get('high_1', 0) + 1\n",
    "            if filled(bar_1['low'], _highest, _lowest):\n",
    "                count_success[_pattern]['low_1'] = count_success[_pattern].get('low_1', 0) + 1\n",
    "            if filled(bar_1['close'], _highest, _lowest):\n",
    "                count_success[_pattern]['close_1'] = count_success[_pattern].get('close_1', 0) + 1\n",
    "\n",
    "    return pattern_labels, count_totals, count_success\n",
    "\n",
    "\n",
    "def select_patterns(count_totals: Dict[str, int], count_success: Dict[str, Dict[str, int]], \n",
    "                    success_rate_threshold: float = 0.75, total_count_threshold: int = 100) -> List[Signal]:\n",
    "    \"\"\"\n",
    "    Selects pattern codes and targets that achieve over a specified success rate and total count.\n",
    "\n",
    "    Parameters:\n",
    "    - count_totals (Dict[str, int]): Dictionary with total counts of each pattern.\n",
    "    - count_success (Dict[str, Dict[str, int]]): Dictionary with success counts for each pattern in different categories.\n",
    "    - success_rate_threshold (float): The minimum success rate required to select a pattern. Default is 0.80.\n",
    "    - total_count_threshold (int): The minimum total count required to select a pattern. Default is 100.\n",
    "\n",
    "    Returns:\n",
    "    - selected_patterns (List[Signal]): A list of Signal namedtuples containing selected patterns with their success rates.\n",
    "    \"\"\"\n",
    "    if not (set(count_totals.keys()) == set(count_success.keys())):\n",
    "        raise ValueError(\"Keys in count_totals and count_success do not match.\")\n",
    "    \n",
    "    patterns = []\n",
    "\n",
    "    for pattern in count_totals.keys():\n",
    "        if count_totals[pattern] > total_count_threshold:\n",
    "            for target in count_success[pattern].keys():\n",
    "                success_rate = count_success[pattern][target] / count_totals[pattern]\n",
    "                if success_rate > success_rate_threshold:\n",
    "                    signal = Signal(\n",
    "                        pattern=pattern,\n",
    "                        target=target,\n",
    "                        success_rate=round(success_rate, 3)\n",
    "                    )\n",
    "                    patterns.append(signal)\n",
    "    \n",
    "    # Sort the selected patterns by success rate in descending order\n",
    "    patterns.sort(reverse=True)\n",
    "\n",
    "    # In case of two signals with the same pattern code, select the signal with the higher success rate\n",
    "    # Create a dictionary to store the maximum success rate for each pattern code\n",
    "    max_success_rate = []\n",
    "    selected_patterns = []\n",
    "\n",
    "    for signal in patterns:\n",
    "        if signal.pattern not in max_success_rate:\n",
    "            max_success_rate.append(signal.pattern)\n",
    "            selected_patterns.append(signal)\n",
    "    \n",
    "    return selected_patterns\n",
    "\n",
    "\n",
    "def generate_target_price(df: pd.DataFrame, selected_patterns: List[Signal], pattern_labels: List[int], hold_period:int=1) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generates target price columns for selected patterns in the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The input DataFrame containing OHLC data.\n",
    "    - selected_patterns (List[Signal]): A list of selected Signal objects.\n",
    "    - pattern_labels (List[int]): A list of pattern labels corresponding to each row in the DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The DataFrame with additional columns for target prices.\n",
    "    \"\"\"\n",
    "    # Create a dictionary for selected patterns with their target columns\n",
    "    selected_patterns_codes = {signal.pattern: signal.target for signal in selected_patterns}\n",
    "\n",
    "    # Make a copy of the DataFrame to avoid modifying the original\n",
    "    df = df.copy()\n",
    "    df['patterns'] = pattern_labels.astype(str)\n",
    "    df['selected'] = df['patterns'].isin(selected_patterns_codes.keys())\n",
    "    df['targets_str'] = ''\n",
    "    \n",
    "    # Create a shifted DataFrame for previous values\n",
    "    df_shift = df.shift(1)\n",
    "\n",
    "    # Assign target columns based on selected patterns\n",
    "    for i in df[df['selected']].index:\n",
    "        df.loc[i, 'targets_str'] = selected_patterns_codes[df.loc[i, 'patterns']]\n",
    "\n",
    "    # Define the conditions and corresponding values for target price selection\n",
    "    select_conditions = [\n",
    "        (df['targets_str'] == 'open'),\n",
    "        (df['targets_str'] == 'high'),\n",
    "        (df['targets_str'] == 'low'),\n",
    "        (df['targets_str'] == 'close'),\n",
    "        (df['targets_str'] == 'open_1'),\n",
    "        (df['targets_str'] == 'high_1'),\n",
    "        (df['targets_str'] == 'low_1'),\n",
    "        (df['targets_str'] == 'close_1')\n",
    "    ]\n",
    "    select_values = [\n",
    "        df['open'], df['high'], df['low'], df['close'], \n",
    "        df_shift['open'], df_shift['high'], df_shift['low'], df_shift['close']\n",
    "    ]\n",
    "\n",
    "    # Generate the 'targets' column based on conditions and values\n",
    "    df['targets'] = np.select(select_conditions, select_values, default=np.nan)\n",
    "\n",
    "    # Forward fill the targets for the holding period\n",
    "    df['targets'] = df['targets'].ffill(limit=hold_period)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CODE FOR REGIME IDENTIFICATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_regime(dataframe, atr_threshold=0.5, inactive_period=10, ema_length=22):\n",
    "    \"\"\"\n",
    "    Compute the regime based on the given dataframe and parameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = dataframe.copy()\n",
    "\n",
    "    atr = ta.atr(df['high'], df['low'], df['close'], 14)\n",
    "    ema = ta.ema(df['close'], ema_length)\n",
    "\n",
    "    minamp = atr * atr_threshold\n",
    "    bodysize = np.absolute(df['open'] - df['close'])\n",
    "    strong_bar = bodysize >= minamp\n",
    "    strong_bull = strong_bar & (df['open'] < df['close'])\n",
    "    strong_bear = strong_bar & (df['open'] > df['close'])\n",
    "\n",
    "    list_regime = []\n",
    "    list_inactive_count = []\n",
    "\n",
    "    regime = 0\n",
    "    inactive_count = 0\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        _close = df['close'].iloc[i]\n",
    "        _ema = ema.iloc[i]\n",
    "        _strong_bull = strong_bull.iloc[i]\n",
    "        _strong_bear = strong_bear.iloc[i]\n",
    "        \n",
    "        # For Neutral Regime\n",
    "        if regime == 0:\n",
    "            if _strong_bull and (_close > _ema):\n",
    "                regime = 2\n",
    "                inactive_count = 0\n",
    "        \n",
    "            elif _strong_bear and (_close < _ema):\n",
    "                regime = -2\n",
    "                inactive_count = 0\n",
    "\n",
    "        # For Bullish Regime\n",
    "        elif regime > 0:\n",
    "            if _strong_bull:\n",
    "                regime = +2 # Reinforce Regime\n",
    "                inactive_count = 0 # Reset count with every significant move\n",
    "\n",
    "            else:\n",
    "                # Count insignificant moves\n",
    "                inactive_count += 1\n",
    "                \n",
    "                # Check for maximum inactive period\n",
    "                if inactive_count >= inactive_period:\n",
    "                    regime = 0\n",
    "\n",
    "                elif _strong_bear:\n",
    "                    # Regime switched to Bearish\n",
    "                    if _close < _ema:\n",
    "                        regime = -2\n",
    "\n",
    "                    # Weak Bullish Regime\n",
    "                    else:\n",
    "                        regime = 1\n",
    "                \n",
    "\n",
    "        # For Bearish Regime\n",
    "        elif regime < 0:\n",
    "            if _strong_bear:\n",
    "                regime = -2 # Reinforce Regime\n",
    "                inactive_count = 0 # Reset count with every significant move\n",
    "            \n",
    "            else:\n",
    "                # Count insignificant moves\n",
    "                inactive_count += 1\n",
    "\n",
    "                # Check for maximum inactive period\n",
    "                if inactive_count >= inactive_period:\n",
    "                    regime = 0\n",
    "\n",
    "                # Reg ime switched to Bearish\n",
    "                elif _strong_bull:\n",
    "                    if _close > _ema:\n",
    "                        regime = 2\n",
    "\n",
    "                    # Weak Bearish Regime\n",
    "                    else:\n",
    "                        regime =-1\n",
    "            \n",
    "        list_regime.append(regime)\n",
    "        list_inactive_count.append(inactive_count)\n",
    "\n",
    "    labels = np.where(\n",
    "        np.array(list_regime) > 0, 1,\n",
    "        np.where(\n",
    "            regime < 0, -1,\n",
    "             0\n",
    "        )\n",
    "    )\n",
    "    return labels\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "source_timeframe = \"1H\"\n",
    "oos_date_start = \"2023-01-01\"\n",
    "hold_period = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE\n",
    "source_df = resample_data(raw_df, source_timeframe, 'time')\n",
    "\n",
    "# Find and select patterns that achieve over 70% success rate, and the total count is more than 50\n",
    "pattern_labels, count_totals, count_success = find_patterns(source_df, hold_period, oos_date_start, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_patterns = select_patterns(count_totals, count_success, total_count_threshold=1000)\n",
    "\n",
    "# Generate the target price columns based on the selected patterns\n",
    "target_df = generate_target_price(source_df, selected_patterns, pattern_labels)\n",
    "\n",
    "dates_list = []\n",
    "for i in target_df[target_df['selected']].index:\n",
    "    start_index = i + 1\n",
    "    end_index = min(i + hold_period + 1, len(target_df) - 1 )\n",
    "\n",
    "    if start_index > len(target_df) - 1:\n",
    "        break\n",
    "\n",
    "    dates_list.append((target_df.loc[start_index, 'time'], target_df.loc[end_index, 'time'], target_df.loc[i, 'targets']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add regime filter\n",
    "target_df['regime'] = compute_regime(target_df)\n",
    "\n",
    "# Add setup direction\n",
    "target_df['direction'] = np.where(\n",
    "    (target_df['targets'] < target_df['close']),\n",
    "    -1,\n",
    "    np.where(\n",
    "        (target_df['targets'] > target_df['close']),\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    ")\n",
    "\n",
    "# Apply regime filter condition\n",
    "target_df['regime_filter'] = \\\n",
    "    (target_df['regime'] < 0) & (target_df['direction'] == -1) | \\\n",
    "        (target_df['regime'] > 0) & (target_df['direction'] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Signal(pattern=000101, target=high, success_rate=0.8)]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'000101'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'high'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "str_patterns = ''\n",
    "str_targets = ''\n",
    "\n",
    "for signal in selected_patterns:\n",
    "    str_patterns += str(signal.pattern) + ';'\n",
    "    str_targets += str(signal.target) + ';'\n",
    "\n",
    "display(str_patterns.strip(';'))\n",
    "display(str_targets.strip(';'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_setup(start_date, end_date, target, direction, entry=None, stop=None, timeframe=None):\n",
    "    # Get the dataframe\n",
    "    df = raw_df.copy()\n",
    "\n",
    "    if isinstance(direction, (int,float)):\n",
    "        direction = 'long' if direction == 1 else 'short'\n",
    "        \n",
    "    print(direction, type(direction))\n",
    "\n",
    "    if timeframe is not None:\n",
    "        # Resample raw_df to the timeframe\n",
    "        df = resample_data(raw_df, timeframe, 'time')\n",
    "\n",
    "    # Filter the DataFrame based on the date range\n",
    "    df = df[(df['time'] >= start_date) & (df['time'] <= end_date)]\n",
    "    print(df)\n",
    "\n",
    "    active_trade = False\n",
    "\n",
    "    entry = entry if entry is not None else df.loc[df.index[0], 'open']\n",
    "\n",
    "    if stop is None:\n",
    "        if direction == 'long':\n",
    "            stop = 0\n",
    "        elif direction == 'short':\n",
    "            stop = df['high'].max() + 1\n",
    "\n",
    "    # Iterate through the DataFrame\n",
    "    for i in range(len(df)):\n",
    "        _high = df['high'].iloc[i]\n",
    "        _low = df['low'].iloc[i]\n",
    "\n",
    "        if filled(entry, _high, _low):\n",
    "            active_trade = True\n",
    "\n",
    "        if not active_trade:\n",
    "            continue\n",
    "        \n",
    "        if direction == 'long':\n",
    "            if _high >= target:\n",
    "                return (target - entry) / entry\n",
    "            elif _low <= stop:\n",
    "                return (stop - entry) / entry\n",
    "        elif direction == 'short':\n",
    "            if _low <= target:\n",
    "                return (entry - target) / entry\n",
    "            elif _high >= stop:\n",
    "                return (entry - stop) / entry\n",
    "            \n",
    "    \n",
    "\n",
    "    # If no return is calculated, return the percentage chnage between the first open and the last close\n",
    "    if direction == 'long':\n",
    "        return (df['close'].loc[df.index[-1]] - entry) / entry\n",
    "    elif direction == 'short':\n",
    "        return (entry - df['close'].loc[df.index[-1]]) / entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "direction=target_df.loc[target_df['time'] == dates_list[1][0], 'direction'].iat[0], "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 <class 'numpy.int64'>\n",
      "                    time    open    high     low   close  volume\n",
      "2697 2001-01-09 15:00:00  1.4970  1.4972  1.4970  1.4972       0\n",
      "2698 2001-01-09 15:03:00  1.4971  1.4971  1.4970  1.4970       0\n",
      "2699 2001-01-09 15:04:00  1.4971  1.4971  1.4970  1.4970       0\n",
      "2700 2001-01-09 15:05:00  1.4972  1.4972  1.4972  1.4972       0\n",
      "2701 2001-01-09 15:07:00  1.4970  1.4970  1.4969  1.4969       0\n",
      "2702 2001-01-09 15:09:00  1.4971  1.4971  1.4969  1.4970       0\n",
      "2703 2001-01-09 15:11:00  1.4965  1.4965  1.4963  1.4963       0\n",
      "2704 2001-01-09 15:22:00  1.4961  1.4961  1.4961  1.4961       0\n",
      "2705 2001-01-09 15:24:00  1.4962  1.4962  1.4962  1.4962       0\n",
      "2706 2001-01-09 15:25:00  1.4961  1.4961  1.4961  1.4961       0\n",
      "2707 2001-01-09 15:26:00  1.4962  1.4962  1.4962  1.4962       0\n",
      "2708 2001-01-09 15:27:00  1.4961  1.4961  1.4959  1.4959       0\n",
      "2709 2001-01-09 15:28:00  1.4958  1.4958  1.4955  1.4956       0\n",
      "2710 2001-01-09 15:30:00  1.4955  1.4957  1.4955  1.4957       0\n",
      "2711 2001-01-09 15:31:00  1.4958  1.4959  1.4958  1.4959       0\n",
      "2712 2001-01-09 15:32:00  1.4958  1.4958  1.4957  1.4957       0\n",
      "2713 2001-01-09 15:36:00  1.4956  1.4956  1.4956  1.4956       0\n",
      "2714 2001-01-09 15:38:00  1.4957  1.4957  1.4957  1.4957       0\n",
      "2715 2001-01-09 15:39:00  1.4956  1.4957  1.4956  1.4957       0\n",
      "2716 2001-01-09 15:42:00  1.4958  1.4958  1.4957  1.4957       0\n",
      "2717 2001-01-09 15:43:00  1.4959  1.4959  1.4959  1.4959       0\n",
      "2718 2001-01-09 15:46:00  1.4958  1.4958  1.4958  1.4958       0\n",
      "2719 2001-01-09 15:50:00  1.4959  1.4959  1.4959  1.4959       0\n",
      "2720 2001-01-09 15:51:00  1.4958  1.4958  1.4958  1.4958       0\n",
      "2721 2001-01-09 15:52:00  1.4955  1.4955  1.4950  1.4950       0\n",
      "2722 2001-01-09 15:53:00  1.4949  1.4949  1.4948  1.4948       0\n",
      "2723 2001-01-09 15:57:00  1.4947  1.4947  1.4946  1.4946       0\n",
      "2724 2001-01-09 15:58:00  1.4944  1.4946  1.4943  1.4943       0\n",
      "2725 2001-01-09 16:00:00  1.4938  1.4940  1.4935  1.4940       0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dates_list)):\n",
    "    print(analyse_setup(\n",
    "        start_date=dates_list[i][0],\n",
    "        end_date=dates_list[i][1],\n",
    "        target=target_df.loc[target_df['time'] == dates_list[i][0], 'targets'].iat[0],\n",
    "        direction=target_df.loc[target_df['time'] == dates_list[i][0], 'direction'].iat[0],\n",
    "    ))\n",
    "\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODEL 1 : Enter when price is X% away from the "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
